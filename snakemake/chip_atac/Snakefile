configfile: "config.yaml"
SAMPLES=config["SAMPLES"]
GENOME=config["GENOME"]
INDEX=GENOME+".sa"
MQ_MIN=config["MQ_MIN"]
BIN_SIZE=config["BIN_SIZE"]
chrM=config["chrM"]
GSIZE=config["GSIZE"]
SizeFile=config["SizeFile"]

# load modules (have to use """, to keep in one block)
# - alias does not work, have to use $samstat
shell.prefix("""
            #source /home/rl44w/.bash_profile
            #echo "## snake.prefix"
            HOME=/home/rl44w/
            samtools="singularity exec $HOME/singularity/hand_sandbox/ samtools"
            samstat="singularity exec $HOME/singularity/hand_sandbox samstat" # alias in .bash_profile not working in snakemake
            bedGraphToBigWig="singularity exec $HOME/singularity/hand_sandbox bedGraphToBigWig"
            """)

# Requirements
# inputs in ./fastq/
# named as {sample}.{R1,R2}.{fastq,fq}.gz
# e.g. A.R1.fastq.gz A.R2.fastq.gz B...


rule all:
    input:
        # 1. everything listed here will be produced by the pipeline
        # 2. feed {sample}
        fastqc="fastqc/multiqc_report.html", # not in main workflow, so list here
        cleanBam=expand("cleanBam/{sample}.bam", sample=SAMPLES),
        Genrich=expand("Genrich/{sample}.bw", sample=SAMPLES) if config["atac"] else "Workflow_DAG.all.svg",
        MACS=expand("macs2/{sample}_peaks.narrowPeak", sample=SAMPLES),
        bam_qc_cleanBam=expand("bam_qc_cleanBam/samstat/{sample}.bam.samstat.html", sample=SAMPLES), # feed {samples}, ensure aligment 
        bam_qc_markDup=expand("bam_qc_markDup/samstat/{sample}.bam.samstat.html", sample=SAMPLES), # feed {samples}, ensure aligment 
        bamCoverage=expand("bigWig/{sample}.cpm.bw", sample=SAMPLES),
        bamPEFragmentSize="chip_qc/fragment_size.pdf",
        insert_size=expand("bam_qc/{sample}.insert_size.pdf", sample=SAMPLES),
        plotFingerprint="chip_qc/fingerprint.pdf",
        plotCorrelation="chip_qc/multiBamSummary.heatmap.pdf",
        plotPCA="chip_qc/multiBamSummary.pca.pdf",
        dag="Workflow_DAG.all.svg", # create DAG


rule fastqc:
    # don't need input, if you agree on not checking them
    # without output, output will not be created
    output:
        "fastqc/multiqc_report.html"
    params:
        mem="1000"
    threads:
        8
    log:
        "log/fastqc/fastqc.log"
    shell:
        # {input/output} don't have to be in command
        # have to load module in one block
        """
        module load fastqc/0.11.5
        mkdir -p fastqc
        mkdir -p fastqc/details
        fastqc -t {threads} fastq/*q.gz -o fastqc/details &> {log}
        multiqc fastqc/details -o fastqc &>> {log}
        """


rule bwa_index:
    input:
        GENOME
    output:
        INDEX
    shell:
        """
        bwa index -a bwtsw {input} &> {log}
        """

# rule trimmomatic:
#     input:
#         r1="fastq/{sample}.R1.fastq.gz",
#         r2="fastq/{sample}.R2.fastq.gz", 
#     output:
#         o1="fastq/{sample}.trim.R1.fastq.gz"
#         o2="fastq/{sample}.trim.R2.fastq.gz"
#         t1="fastq/trash/{sample}.trash.R1.fastq.gz"
#         t2="fastq/trash/{sample}.trash.R2.fastq.gz"
#     params:
#         mem="8000"
#     threads:
#         2
#     conda:
#         "envs/trimmomatic.yaml"
#     log:
#         "log/trimmomatic/{sample}.trim.log"
#     benchmark:
#         "log/trimmomatic/{sample}.trim.benchmark.txt"
#     shell:
#         """
#         trimmomatic PE -threads {threads} {input.r1} {input.r2} \
#         {output.o1}  {output.t1} {output.o2}{output.t2} \
#         ILLUMINACLIP:$adaptor:2:30:10 \
#         LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 \
#         TOPHRED33
#         """



rule bwa_map:
    # 1min/1M reads with 16 cores
    input:
        index=INDEX,
        r1="fastq/{sample}.R1.fastq.gz",
        r2="fastq/{sample}.R2.fastq.gz",
    output:
        temp("mapped_reads/{sample}.bam")
    params:
        mem="1500"  # todo auto adjust based on {threads}, for human need 18G+ 
    conda:
        "envs/samtools.yaml"
    threads:
        16
    log:
        "log/bwa_map/{sample}.bwa.log"
    benchmark:
        "log/bwa_map/{sample}.bwa.benchmark.txt"
    shell:
        """
        bwa mem -t {threads} {GENOME} \
        {input.r1} {input.r2} \
        2> {log}| samtools view -Sb -1 -@ 2 - -o {output} &>> {log}
        """


rule samtools_sort_index:
    # 2M/min
    input:
        "mapped_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam"
    params:
        mem="1200"
    conda:
        "envs/samtools.yaml"
    threads:
        4
    log:
        "log/samtools_sort/{sample}.sort.log"
    shell:
        """
        samtools --version &> {log}
        samtools sort -@ {threads} -m 1G {input} -o {output} &>> {log}
        samtools index {output} &>> {log}
        """



rule markDup:
    # same speed as bwa_map, slow
    input:
        "sorted_reads/{sample}.bam"
    output:
        #temp(
        bam="markDup/{sample}.bam",
        metrics="markDup/{sample}.markDup_metrics.txt",
        bai="markDup/{sample}.bam.bai",
        #)  # make temp and save storage
    log:
        "log/markDup/{sample}.markDup.log"
    benchmark:
        "log/markDup/{sample}.benchmark.txt"
    conda:
        "envs/samtools.yaml"
    threads:
        2
    params:
        mem="16000",  # Used Max of 24G before
    shell:
        """
        module load picard/2.17.8
        PICARD=/share/pkg/picard/2.17.8/picard.jar
        
        java -Xmx30g -XX:ParallelGCThreads=2 -jar $PICARD MarkDuplicates \
        I={input} \
        O={output.bam} \
        M={output.metrics} \
        REMOVE_DUPLICATES=true \
        ASSUME_SORTED=true \
        &> {log}

        samtools index {output.bam} &>> {log}
        """

rule cleanBam:
    input:
        "markDup/{sample}.bam"
    output:
        "cleanBam/{sample}.bam"
    log:
        "log/cleanBam/{sample}.log"
    benchmark:
        "log/cleanBam/{sample}.benchmark.txt"
    threads:
        2
    params:
        mem="8000"
    conda:
        "envs/samtools.yaml"
    shell:
        """
        if [ {config[atac]} ]; then
            echo 'ATACseq mode'
            echo {input}
            echo 'remove mito reads; keep paired reads with MQ>20 and 38-2000nt fragment size only'
            samtools view -h {input} 2>{log}| perl -lane 'print unless ($F[2] eq {chrM} and $_ != /\@/)' 2>>{log}| awk \'{config[filter]}\' 2>>{log}| $samtools sort -m 8G -o {output}  2>> {log}
        else
            echo 'ChIPseq mode'
            echo 'No filtering'
            cp {input} {output}
        fi

        samtools index {output} &> {log}
        """

rule bam_qc_markDup:
    input:
        bam="markDup/{sample}.bam"
    output:
        samstat="bam_qc_markDup/samstat/{sample}.bam.samstat.html",
        idxstats="bam_qc_markDup/idxstats/{sample}.idxstats.txt",
        flagstat="bam_qc_markDup/flagstat/{sample}.flagsat.txt",
        stats="bam_qc_markDup/stats/{sample}.stats.txt"
    params:
        mem="3000"
    conda:
        "envs/samtools.yaml"
    threads:
        4
    log:
        idxstats="log/bam_qc_markDup/idxstats/{sample}.idxstats.log",
        flagstat="log/bam_qc_markDup/flagstat/{sample}.flagstat.log",
        stats="log/bam_qc_markDup/stats/{sample}.stats.log",
        samstat="log/bam_qc_markDup/samstat/{sample}.samstat.log",
    shell:
        """
        samtools idxstats {input.bam} > {output.idxstats} 2> {log.idxstats} &
        samtools flagstat {input.bam} > {output.flagstat} 2> {log.flagstat} &
        samtools stats {input.bam} > {output.stats} 2> {log.stats} &
        $samstat {input.bam} && mv markDup/{wildcards.sample}.bam.samstat.html bam_qc_markDup/samstat > {log.samstat} 2>&1 &
        wait
        """

rule bam_qc_cleanBam:
    input:
        bam="cleanBam/{sample}.bam"
    output:
        samstat="bam_qc_cleanBam/samstat/{sample}.bam.samstat.html",
        idxstats="bam_qc_cleanBam/idxstats/{sample}.idxstats.txt",
        flagstat="bam_qc_cleanBam/flagstat/{sample}.flagsat.txt",
        stats="bam_qc_cleanBam/stats/{sample}.stats.txt"
    params:
        mem="2000"
    conda:
        "envs/samtools.yaml"
    threads:
        6
    log:
        idxstats="log/bam_qc_cleanBam/idxstats/{sample}.idxstats.log",
        flagstat="log/bam_qc_cleanBam/flagstat/{sample}.flagstat.log",
        stats="log/bam_qc_cleanBam/stats/{sample}.stats.log",
        samstat="log/bam_qc_cleanBam/samstat/{sample}.samstat.log",
    shell:
        """
        samtools idxstats {input.bam} > {output.idxstats} 2> {log.idxstats} &
        samtools flagstat {input.bam} > {output.flagstat} 2> {log.flagstat} &
        samtools stats {input.bam} > {output.stats} 2> {log.stats} &
        $samstat {input.bam} && mv cleanBam/{wildcards.sample}.bam.samstat.html bam_qc_cleanBam/samstat > {log.samstat} 2>&1 &
        wait
        """

rule SortBamByNameForGenrich:
    input:
        "cleanBam/{sample}.bam"
    output:
        "cleanSortByName/{sample}.bam"
    conda:
      "envs/samtools.yaml"
    threads:
        2
    params:
        mem="2500"
    benchmark:
        "log/cleanSortByName/{sample}.benchmark.txt"
    shell:
        "samtools sort -n -@ 2 -m 2G {input} -o {output}"


rule Genrich:
    input:
        "cleanSortByName/{sample}.bam"
    output:
        peak="Genrich/{sample}.narrowPeak",
        bedGraph="Genrich/{sample}.bedgraph_ish"
    threads:
        1
    params:
        mem="16000"  # not sure yet
    log:
        "log/Genrich/{sample}.log"
    run:
        if config["atac"]:
            print("Genrich ATACseq mode")
            # todo: merge reps
            shell("Genrich -t {input} -o {output.peak} -k {output.bedGraph} -j -y -e {chrM} -m {MQ_MIN} -v &>{log}")
        else:
            # should not exist by setting in rule 'all'
            print("Genrich ChIP mode")
            shell("Genrich -t {input} -o {output.peak} -x -m {MQ_MIN} &> {log}")

rule genrich_bdgToBigWig:
    input:
        "Genrich/{sample}.bedgraph_ish"
    output:
        "Genrich/{sample}.bw"
    threads:
        1
    params:
        mem="8000"
    log:
        "log/genrich_bdgToBigWig/{sample}.log"
    benchmark:
        "log/genrich_bdgToBigWig/{sample}.benchmark.txt"
    shell:
        """
        tail -n +3 {input} | cut -f 1,2,3,6 | sort -k1,1 -k2,2n > Genrich/{wildcards.sample}.bdg
        $bedGraphToBigWig Genrich/{wildcards.sample}.bdg {SizeFile} {output} && \
        rm -f Genrich/{wildcards.sample}.bdg
        """


rule macs2:
    input:
        "cleanBam/{sample}.bam"
    output:
        "macs2/{sample}_peaks.narrowPeak"
    threads:
        1
    params:
        mem="12000"
    log:
        "log/macs/{sample}.log"
    shell:
        """
        source activate py27
        macs2 callpeak -t {input} -f BAMPE -g {GSIZE} -q 0.05 --keep-dup all -n {wildcards.sample} --outdir macs2 -B 
        """

rule bamCoverage:
    # for ChIP
    input:
        "cleanBam/{sample}.bam"
    output:
        "bigWig/{sample}.cpm.bw"
    threads:
        8
    params:
        mem="1500"  # total 6-10G
    log:
        "log/bamCoverage/{sample}.bamCoverage.log"
    shell:
        # Aim: same as our downstream filters, extensions
        """
        bamCoverage --bam {input} \
        -o  {output} \
        --numberOfProcessors {threads} \
        --outFileFormat bigwig \
        --normalizeUsing CPM \
        --minFragmentLength {config[minFragmentLength]} \
        --maxFragmentLength {config[maxFragmentLength]} \
        --binSize 10 \
        -e 150 &> {log}
        """


rule plotFingerprint:
    input:
        expand("cleanBam/{sample}.bam", sample=SAMPLES)
    output:
        plot="chip_qc/fingerprint.pdf",
        txt="chip_qc/fingerprint.txt",
    params:
        mem="2000"
    threads:
        6
    log:
        "log/chip_qc/fingerprint.log"
    shell:
        """
        plotFingerprint -b {input} \
            --plotFile {output.plot} \
            --outRawCounts {output.txt} \
            --plotTitle "Fingerprint Plot" \
            --smartLabels \
            --minMappingQuality {MQ_MIN} \
            --binSize {BIN_SIZE} \
            --minFragmentLength {config[minFragmentLength]} \
            --maxFragmentLength {config[maxFragmentLength]} \
            --extendReads \
            --centerReads \
            --samFlagInclude 2 \
            -p {threads} &> {log}
        """
        # --samFlagInclude 2: mate properly paired only
        # --extendReads: use mate into


rule bamPEFragmentSize:
    input:
        expand("cleanBam/{sample}.bam", sample=SAMPLES)
    output:
        plot="chip_qc/fragment_size.pdf",
        txt="chip_qc/fragment_size.txt"
    params:
        mem="4000"
    threads:
        4
    log:
        "log/chip_qc/fragment_size.log"
    shell:
        """
        bamPEFragmentSize \
        -hist {output.plot} \
        --outRawFragmentLengths {output.txt} \
        -T "Fragment Size Distribution" \
        --maxFragmentLength 1500 \
        -b {input} \
        -p {threads} &> {log}
        """


rule multiBamSummary:
    input:
        expand("cleanBam/{sample}.bam", sample=SAMPLES)
    output:
        "chip_qc/multiBamSummary.npz",
    threads:
        8
    params:
        mem="3500"
    log:
        "log/chip_qc/multiBamSummary.log"
    shell:
        """
        multiBamSummary bins \
        -b {input} \
        -o {output} \
        --binSize {BIN_SIZE} \
        --smartLabels \
        -p {threads} \
        --minMappingQuality {MQ_MIN} \
        --minFragmentLength {config[minFragmentLength]} \
        --maxFragmentLength {config[maxFragmentLength]} \
        -e \
        --samFlagInclude 2 &> {log}
        """
        

rule plotCorrelation:
    input:
        "chip_qc/multiBamSummary.npz",
    output:
        "chip_qc/multiBamSummary.heatmap.pdf"
    threads:
        1
    params:
        mem="12000"
    log:
        "log/chip_qc/plotCorrelation.log"
    shell:
        """
        plotCorrelation \
        -in {input} \
        --corMethod pearson --skipZeros \
        --whatToPlot heatmap \
        -T 'Pearson Corr Between Bins' \
        --removeOutliers \
        -o {output} &> {log}
        """

rule plotPCA:
    input:
        "chip_qc/multiBamSummary.npz",
    output:
        "chip_qc/multiBamSummary.pca.pdf"
    threads:
        1
    params:
        mem="20000"
    log:
        "log/chip_qc/plotPCA.log"
    shell:
        """
        plotPCA \
        --corData {input} \
        --plotFile {output} &> {log}
        """

rule CollectInsertSizeMetrics:
    input:
        "cleanBam/{sample}.bam"
    output:
        txt="bam_qc/{sample}.insert_size.txt",
        pdf="bam_qc/{sample}.insert_size.pdf"
    threads:
        1
    params:
        mem="16000"
    shell:
        """
        module load picard/2.17.8
        PICARD=/share/pkg/picard/2.17.8/picard.jar

        java -Xmx15g -jar $PICARD CollectInsertSizeMetrics \
        I={input} \
        O={output.txt} \
        H={output.pdf}
        """ 




rule epic2:
    input:
        "cleanBam/{sample}.bam"
    output:
        "epic2/{sample}.peak"
    threads:
        4
    params:
        mem="2000"
    shell:
        """
        epic2 -h
        """

rule create_dag:
    params:
        mem="1000"  
        # every job has to have this defined 
        # to use snakemake --cluster 'bsub -q short -R "rusage[mem={params.mem}]" -n {threads}'
    threads:
        1
    output:
        "Workflow_DAG.all.svg"
    log:
        "log/create_dag/Workflow_DAG.all.svg.log"
    shell:
        "snakemake --dag all | dot -Tsvg > {output} 2> {log}"


rule reset:
    shell:
        """
        rm -rf fastqc bam_qc/ bigWig/ 
        rm -rf lsf.log *svg *html log nohup.out chip_qc/
        rm -rf genrich/ Genrich/ macs2/ 
        echo "awk \'{config[filter]}\' "
        snakemake --unlock
        """
